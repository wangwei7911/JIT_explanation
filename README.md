## JIT_explanation
为了验证基于知识蒸馏的缺陷预测结果可解释性分析，我们选择LIME 方法作为基线方法。通过和基线方法进行对比，我们试图回答以下问题
- (RQ1) 是否具有局部可解释性。
- (RQ2) 对比于 LIME 方法，我们方法的优势。
LIME解释结果具有不稳定的特点。而软决策树模型一旦生成，其决策路径便已固定，不存在对同一个实例进行多次解释时出现不同的解释结果的问题，更加稳定。除此以外，LIME方法用户无法判断拟合的线性模型决策过程与深度网络的决策过程是否一致，其解释结果是不透明的。本文生成的模型属于对用户友好的决策树模型，决 策树模型的特点是模型每作出一个决策都会通过一个决策序列来向我们展示模型的决策依据，即 将决策过程以 if-then 的方式展现为决策路径。借助知识蒸馏我们可以将 teacher 网络的决策知识 转化为决策树的决策路径，提高了决策结果的透明性。因此，我们认为相较于 LIME 方法，本文 方法更加稳定，更加透明。
